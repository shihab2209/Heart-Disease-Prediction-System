# -*- coding: utf-8 -*-
"""CSE_422_Group11_HEART_DISEASE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vkhS0ZBQBBNYM_8OnIbqr2gru8oqRnIP
"""

#importing libraries

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
print(os.listdir())
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split

#@title Default title text
#importing dataset

dataset = pd.read_csv("/content/heart1.csv")

type(dataset)

"""# New Section"""

#shape

dataset.shape

#printing first 5 columns

dataset.head(5)

#printing any 5 columns

dataset.sample(5)

#description

dataset.describe()

dataset.info()

info = ["age","1: male, 0: female","chest pain type, 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic","resting blood pressure"," serum cholestoral in mg/dl","fasting blood sugar > 120 mg/dl","resting electrocardiographic results (values 0,1,2)"," maximum heart rate achieved","exercise induced angina","oldpeak = ST depression induced by exercise relative to rest","the slope of the peak exercise ST segment","number of major vessels (0-3) colored by flourosopy","thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"]



for i in range(len(info)):
    print(dataset.columns[i]+":\t\t\t"+info[i])

#analysing

dataset["target"].describe()

#it is a classification problem

#checking correlation

print(dataset.corr()["target"].abs().sort_values(ascending=False))

#fbs weakly correlated

y = dataset["target"]

sns.countplot(y)

#analyzing target variable

y = dataset["target"]

sns.countplot(y)


target_temp = dataset.target.value_counts()

print(target_temp)

print("Percentage of patience without heart problems: "+str(round(target_temp[0]*100/303,2)))
print("Percentage of patience with heart problems: "+str(round(target_temp[1]*100/303,2)))

#analysing "sex" feature

dataset["sex"].unique()

#2 unique features

#females are more likely to have heart problems than male

sns.barplot(dataset["sex"],y)

#analysing "chest pain type" feature

dataset["cp"].unique()

#has values from 0 to 3

# CP of "0" that is typical angina are much less likely to have heart problems

sns.barplot(dataset["cp"],y)

#analysing "FBS" feature

dataset["fbs"].describe()

dataset["fbs"].unique()

sns.barplot(dataset["fbs"],y)

#analysing "restecg" feature

dataset["restecg"].unique()

sns.barplot(dataset["restecg"],y)

#people with R 1 and 0 are much more likely to have heart desease than R 2

#analysing "exang" feature

dataset["exang"].unique()

sns.barplot(dataset["exang"],y)

#people with E1, that is exercise induced angina are much less likely to have heart problems

#analysing "slope" feature

dataset["slope"].unique()

sns.barplot(dataset["slope"],y)

# S2 causes heartpain much more than S0 and S1

#analysing "slope" feature

dataset["ca"].unique()

sns.countplot(dataset["ca"])

sns.barplot(dataset["ca"],y)

#CA4 has very high number of heart patients

#anlysing the 'thal' feature

dataset["thal"].unique()

sns.barplot(dataset["thal"],y)

sns.distplot(dataset["thal"])

#TRAIN TEST SPLIT

from sklearn.model_selection import train_test_split

predictors = dataset.drop("target",axis=1)
target = dataset["target"]

X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.30,random_state=1)

X_train.shape

X_test.shape

Y_train.shape

Y_test.shape

## MODEL FITTING ##

from sklearn.metrics import accuracy_score

#LOGISTIC REGRESSION

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train,Y_train)

Y_pred_lr = lr.predict(X_test)

Y_pred_lr.shape

score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)

print("The accuracy score achieved using Logistic Regression is: "+str(score_lr)+" %")

from sklearn.metrics import confusion_matrix
confusion_matrix= confusion_matrix(Y_test,Y_pred_lr)

confusion_matrix

from sklearn import metrics
import numpy as np

actual = Y_test
predicted = Y_pred_lr

confusion_matrix = metrics.confusion_matrix(actual, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, False])

cm_display.plot()
plt.show()

from sklearn.metrics import classification_report

print(classification_report(Y_test,Y_pred_lr))

#DECISION TREE

from sklearn.tree import DecisionTreeClassifier

max_accuracy = 0


for x in range(200):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(X_train,Y_train)
    Y_pred_dt = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
        
#print(max_accuracy)
#print(best_x)


dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,Y_train)
Y_pred_dt = dt.predict(X_test)

print(Y_pred_dt.shape)

score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_dt)+" %")

from sklearn.metrics import confusion_matrix
confusion_matrix= confusion_matrix(Y_test,Y_pred_dt)

confusion_matrix

actual = Y_test
predicted = Y_pred_dt

confusion_matrix = metrics.confusion_matrix(actual, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, False])

cm_display.plot()
plt.show()

from sklearn.metrics import classification_report

print(classification_report(Y_test,Y_pred_dt))

#RANDOM FOREST

from sklearn.ensemble import RandomForestClassifier

max_accuracy = 0


for x in range(2000):
    rf = RandomForestClassifier(random_state=x)
    rf.fit(X_train,Y_train)
    Y_pred_rf = rf.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
        
#print(max_accuracy)
#print(best_x)

rf = RandomForestClassifier(random_state=best_x)
rf.fit(X_train,Y_train)
Y_pred_rf = rf.predict(X_test)

Y_pred_rf.shape

score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_rf)+" %")

from sklearn.metrics import confusion_matrix
confusion_matrix= confusion_matrix(Y_test,Y_pred_rf)

confusion_matrix

actual = Y_test
predicted = Y_pred_rf

confusion_matrix = metrics.confusion_matrix(actual, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, False])

cm_display.plot()
plt.show()

from sklearn.metrics import classification_report

print(classification_report(Y_test,Y_pred_rf))

#NEURAL NETWORK

from keras.models import Sequential
from keras.layers import Dense

# https://stats.stackexchange.com/a/136542 helped a lot in avoiding overfitting

model = Sequential()
model.add(Dense(11,activation='relu',input_dim=13))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(X_train,Y_train,epochs=300)

Y_pred_nn = model.predict(X_test)

Y_pred_nn.shape

rounded = [round(x[0]) for x in Y_pred_nn]

Y_pred_nn = rounded

score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)

print("The accuracy score achieved using Neural Network is: "+str(score_nn)+" %")

#Note: Accuracy of 85% can be achieved on the test set, by setting epochs=2000, and number of nodes = 11.

from sklearn.metrics import confusion_matrix
confusion_matrix= confusion_matrix(Y_test,Y_pred_nn)

confusion_matrix

actual = Y_test
predicted = Y_pred_nn

confusion_matrix = metrics.confusion_matrix(actual, predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, False])

cm_display.plot()
plt.show()

from sklearn.metrics import classification_report

print(classification_report(Y_test,Y_pred_nn))

scores = [score_lr, score_dt,score_rf, score_nn]
algorithms = ["Logistic Regression","Decision Tree","Random Forest","Neural Network"]    

for i in range(len(algorithms)):
    print("The accuracy score achieved using "+algorithms[i]+" is: "+str(scores[i])+" %")

sns.set(rc={'figure.figsize':(10,8)})
dataset_corr = dataset.corr()
dataset_corr

import seaborn as sns

sns.heatmap(dataset_corr, cmap = 'YlGnBu')

sns.set(rc={'figure.figsize':(10,8)})
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")

sns.barplot(algorithms,scores)